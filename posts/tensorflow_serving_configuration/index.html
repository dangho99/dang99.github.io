<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Prepare and Deploy a TensorFlow Model to Tensorflow Serving | Hoangph3's Blog</title><meta name=keywords content="TensorFlow,Model Serving"><meta name=description content="Serve tensorflow model efficiently with customized model signatures"><meta name=author content="dang99"><link rel=canonical href=https://dang99.github.io/posts/tensorflow_serving_configuration/><link crossorigin=anonymous href=../../assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../../assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dang99.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dang99.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dang99.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dang99.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dang99.github.io/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Prepare and Deploy a TensorFlow Model to Tensorflow Serving"><meta property="og:description" content="Serve tensorflow model efficiently with customized model signatures"><meta property="og:type" content="article"><meta property="og:url" content="https://dang99.github.io/posts/tensorflow_serving_configuration/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-06T11:45:22-08:00"><meta property="article:modified_time" content="2022-12-06T11:45:22-08:00"><meta property="og:site_name" content="Hoangph3's blog - Software Engineering Tutorials"><meta name=twitter:card content="summary"><meta name=twitter:title content="Prepare and Deploy a TensorFlow Model to Tensorflow Serving"><meta name=twitter:description content="Serve tensorflow model efficiently with customized model signatures"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://dang99.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Prepare and Deploy a TensorFlow Model to Tensorflow Serving","item":"https://dang99.github.io/posts/tensorflow_serving_configuration/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Prepare and Deploy a TensorFlow Model to Tensorflow Serving","name":"Prepare and Deploy a TensorFlow Model to Tensorflow Serving","description":"Serve tensorflow model efficiently with customized model signatures","keywords":["TensorFlow","Model Serving"],"articleBody":"Prepare and Deploy a TensorFlow Model to Tensorflow Serving In this lab, we will:\nDownloading and running the ResNet module Creating serving signatures for the module Exporting the model as a SavedModel Deploying the SavedModel to AI Platform Prediction Validating the deployed model Advanced model server configuration: WarmUp, Batching, … We will export two trained Resnet model, consist of Resnet50 and Resnet101, then serve these.\n1. Download pretrained model from TFHub: $ wget https://storage.googleapis.com/tfhub-modules/google/imagenet/resnet_v2_50/classification/5.tar.gz $ wget https://storage.googleapis.com/tfhub-modules/google/imagenet/resnet_v2_101/classification/5.tar.gz Then extract into a folder, similarity following to:\n$ tree /home/hoang/Downloads/resnet /home/hoang/Downloads/resnet ├── 101 │ ├── saved_model.pb │ └── variables │ ├── variables.data-00000-of-00001 │ └── variables.index └── 50 ├── saved_model.pb └── variables ├── variables.data-00000-of-00001 └── variables.index 4 directories, 6 files Note that the directory 50, same as 101 is the version of the model.\nThe expected input to most TF2.x image classification models, is a rank 4 tensor conforming to the following tensor specification: tf.TensorSpec([None, height, width, 3], tf.float32). More concretely, the expected image size is height x width = 224 x 224. The color values for all channels are expected to be normalized to the [0, 1] range.\nThe output of the model is a batch of logits vectors. The indices into the logits are the num_classes = 1001 classes from the ImageNet dataset. The mapping from indices to class labels can be found in the labels file with class 0 for “background”, followed by 1000 actual ImageNet classes.\nWe will now test the model on a couple of JPEG images.\nDisplay sample images:\n\u003e\u003e\u003e import utils \u003e\u003e\u003e IMAGES_FOLDER=\"images\" \u003e\u003e\u003e image_list = utils.get_image_list(image_dir=IMAGES_FOLDER) \u003e\u003e\u003e utils.show_image(image_list) (720, 498, 3) (600, 512, 3) We get two images and its shape but the images need to be preprocessed to conform to the format expected (224, 224, 3) by the ResNet model.\n\u003e\u003e\u003e size = 224 \u003e\u003e\u003e raw_images = tf.stack(image_list) \u003e\u003e\u003e preprocessed_images = utils.preprocess_image(raw_images, size) \u003e\u003e\u003e preprocessed_images.shape TensorShape([2, 224, 224, 3]) Run inference:\n\u003e\u003e\u003e model = tf.keras.models.load_model('/home/hoang/Downloads/resnet/101') \u003e\u003e\u003e predictions = model(preprocessed_images) \u003e\u003e\u003e predictions \u003ctf.Tensor: shape=(2, 1001), dtype=float32, numpy= array([[ 0.27374715, -1.2126322 , -0.85858756, ..., -1.8846453 , 0.25237346, 1.8259864 ], [ 0.28163522, 0.61459076, -0.00311601, ..., -0.5948272 , -0.05215326, -0.11519516]], dtype=float32)\u003e The model returns a batch of arrays with logits. This is not a very user friendly output so we will convert it to the list of ImageNet class labels.\n\u003e\u003e\u003e import numpy as np \u003e\u003e\u003e imagenet_labels = np.array(open(\"labels/ImageNetLabels.txt\").read().splitlines()) \u003e\u003e\u003e imagenet_labels array(['background', 'tench', 'goldfish', ..., 'bolete', 'ear', 'toilet tissue'], dtype='","wordCount":"1871","inLanguage":"en","datePublished":"2022-12-06T11:45:22-08:00","dateModified":"2022-12-06T11:45:22-08:00","author":[{"@type":"Person","name":"dang99"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://dang99.github.io/posts/tensorflow_serving_configuration/"},"publisher":{"@type":"Organization","name":"Hoangph3's Blog","logo":{"@type":"ImageObject","url":"https://dang99.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dang99.github.io accesskey=h title="Hoangph3's blog (Alt + H)">Hoangph3's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dang99.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dang99.github.io>Home</a>&nbsp;»&nbsp;<a href=https://dang99.github.io/posts/>Posts</a></div><h1 class=post-title>Prepare and Deploy a TensorFlow Model to Tensorflow Serving</h1><div class=post-description>Serve tensorflow model efficiently with customized model signatures</div><div class=post-meta><span title='2022-12-06 11:45:22 -0800 -0800'>December 6, 2022</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1871 words&nbsp;·&nbsp;dang99</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#prepare-and-deploy-a-tensorflow-model-to-tensorflow-serving>Prepare and Deploy a TensorFlow Model to Tensorflow Serving</a><ul><li><a href=#1-download-pretrained-model-from-tfhub>1. Download pretrained model from TFHub:</a></li><li><a href=#2-create-serving-signatures>2. Create Serving Signatures:</a></li><li><a href=#3-save-the-custom-serving-module-as-savedmodel>3. Save the custom serving module as <code>SavedModel</code></a></li><li><a href=#4-deploying-the-savedmodel>4. Deploying the <code>SavedModel</code></a></li><li><a href=#5-validating-the-deployed-model>5. Validating the deployed model</a></li><li><a href=#6-advanced-model-server-configuration>6. Advanced model server configuration</a></li><li><a href=#optional-grpc-vs-rest>(Optional) gRPC vs. REST</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=prepare-and-deploy-a-tensorflow-model-to-tensorflow-serving>Prepare and Deploy a TensorFlow Model to Tensorflow Serving<a hidden class=anchor aria-hidden=true href=#prepare-and-deploy-a-tensorflow-model-to-tensorflow-serving>#</a></h2><p>In this lab, we will:</p><ol><li>Downloading and running the ResNet module</li><li>Creating serving signatures for the module</li><li>Exporting the model as a <code>SavedModel</code></li><li>Deploying the <code>SavedModel</code> to AI Platform Prediction</li><li>Validating the deployed model</li><li>Advanced model server configuration: WarmUp, Batching, &mldr;</li></ol><p>We will export two trained Resnet model, consist of Resnet50 and Resnet101, then serve these.</p><h3 id=1-download-pretrained-model-from-tfhub>1. Download pretrained model from TFHub:<a hidden class=anchor aria-hidden=true href=#1-download-pretrained-model-from-tfhub>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ wget https://storage.googleapis.com/tfhub-modules/google/imagenet/resnet_v2_50/classification/5.tar.gz
</span></span><span style=display:flex><span>$ wget https://storage.googleapis.com/tfhub-modules/google/imagenet/resnet_v2_101/classification/5.tar.gz
</span></span></code></pre></div><p>Then extract into a folder, similarity following to:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ tree /home/hoang/Downloads/resnet
</span></span><span style=display:flex><span>/home/hoang/Downloads/resnet
</span></span><span style=display:flex><span>├── <span style=color:#ae81ff>101</span>
</span></span><span style=display:flex><span>│   ├── saved_model.pb
</span></span><span style=display:flex><span>│   └── variables
</span></span><span style=display:flex><span>│       ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>│       └── variables.index
</span></span><span style=display:flex><span>└── <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>    ├── saved_model.pb
</span></span><span style=display:flex><span>    └── variables
</span></span><span style=display:flex><span>        ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>        └── variables.index
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span> directories, <span style=color:#ae81ff>6</span> files
</span></span></code></pre></div><p>Note that the directory <code>50</code>, same as <code>101</code> is the version of the model.</p><p>The expected input to most TF2.x image classification models, is a rank <code>4</code> tensor conforming to the following tensor specification: <code>tf.TensorSpec([None, height, width, 3], tf.float32)</code>.
More concretely, the expected image size is height x width = <code>224 x 224</code>. The color values for all channels are expected to be normalized to the [0, 1] range.</p><p>The output of the model is a batch of logits vectors. The indices into the logits are the num_classes = <code>1001</code> classes from the ImageNet dataset. The mapping from indices to class labels can be found in the labels file with class <code>0</code> for &ldquo;background&rdquo;, followed by <code>1000</code> actual ImageNet classes.</p><p>We will now test the model on a couple of JPEG images.</p><p>Display sample images:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>import</span> utils
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> IMAGES_FOLDER<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;images&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> image_list <span style=color:#f92672>=</span> utils<span style=color:#f92672>.</span>get_image_list(image_dir<span style=color:#f92672>=</span>IMAGES_FOLDER)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> utils<span style=color:#f92672>.</span>show_image(image_list)
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>720</span>, <span style=color:#ae81ff>498</span>, <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>(<span style=color:#ae81ff>600</span>, <span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>3</span>)
</span></span></code></pre></div><p>We get two images and its shape but the images need to be preprocessed to conform to the format expected <code>(224, 224, 3)</code> by the ResNet model.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> size <span style=color:#f92672>=</span> <span style=color:#ae81ff>224</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> raw_images <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>stack(image_list)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> preprocessed_images <span style=color:#f92672>=</span> utils<span style=color:#f92672>.</span>preprocess_image(raw_images, size)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> preprocessed_images<span style=color:#f92672>.</span>shape
</span></span><span style=display:flex><span>TensorShape([<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>3</span>])
</span></span></code></pre></div><p>Run inference:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>load_model(<span style=color:#e6db74>&#39;/home/hoang/Downloads/resnet/101&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> predictions <span style=color:#f92672>=</span> model(preprocessed_images)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> predictions
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;</span>tf<span style=color:#f92672>.</span>Tensor: shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1001</span>), dtype<span style=color:#f92672>=</span>float32, numpy<span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>array([[ <span style=color:#ae81ff>0.27374715</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1.2126322</span> , <span style=color:#f92672>-</span><span style=color:#ae81ff>0.85858756</span>, <span style=color:#f92672>...</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1.8846453</span> ,
</span></span><span style=display:flex><span>         <span style=color:#ae81ff>0.25237346</span>,  <span style=color:#ae81ff>1.8259864</span> ],
</span></span><span style=display:flex><span>       [ <span style=color:#ae81ff>0.28163522</span>,  <span style=color:#ae81ff>0.61459076</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.00311601</span>, <span style=color:#f92672>...</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.5948272</span> ,
</span></span><span style=display:flex><span>        <span style=color:#f92672>-</span><span style=color:#ae81ff>0.05215326</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>0.11519516</span>]], dtype<span style=color:#f92672>=</span>float32)<span style=color:#f92672>&gt;</span>
</span></span></code></pre></div><p>The model returns a batch of arrays with logits. This is not a very user friendly output so we will convert it to the list of ImageNet class labels.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> imagenet_labels <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(open(<span style=color:#e6db74>&#34;labels/ImageNetLabels.txt&#34;</span>)<span style=color:#f92672>.</span>read()<span style=color:#f92672>.</span>splitlines())
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> imagenet_labels
</span></span><span style=display:flex><span>array([<span style=color:#e6db74>&#39;background&#39;</span>, <span style=color:#e6db74>&#39;tench&#39;</span>, <span style=color:#e6db74>&#39;goldfish&#39;</span>, <span style=color:#f92672>...</span>, <span style=color:#e6db74>&#39;bolete&#39;</span>, <span style=color:#e6db74>&#39;ear&#39;</span>,
</span></span><span style=display:flex><span>       <span style=color:#e6db74>&#39;toilet tissue&#39;</span>], dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&lt;U30&#39;</span>)
</span></span></code></pre></div><h3 id=2-create-serving-signatures>2. Create Serving Signatures:<a hidden class=anchor aria-hidden=true href=#2-create-serving-signatures>#</a></h3><p>The inputs and outputs of the model as used during model training may not be optimal for serving. For example, in a typical training pipeline, feature engineering is performed as a separate step preceding model training and hyperparameter tuning. When serving the model, it may be more optimal to embed the feature engineering logic into the serving interface rather than require a client application to preprocess data.</p><p>The ResNet model from TFHub is optimized for recomposition and fine-tuning. Since there are no serving signatures in the model&rsquo;s metadata, it cannot be served with TF Serving as is.</p><p>To make it servable, we need to add a serving signature(s) describing the inference method(s) of the model. We will add two signatures:</p><ul><li><code>The default signature</code>: this will expose the default predict method of the ResNet model.</li><li><code>Prep/post-processing signature</code>: since the expected inputs to this interface require a relatively complex image preprocessing to be performed by a client, we will also expose an alternative signature that embeds the preprocessing and postprocessing logic and accepts raw unprocessed images and returns the list of ranked class labels and associated label probabilities.</li></ul><p>The signatures are created by defining a custom module class derived from the <code>tf.Module</code> base class. The custom module will be exported as <code>SavedModel</code> that includes the original model, the preprocessing logic, and two serving signatures.</p><p>Test the custom serving module:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> serving_module <span style=color:#f92672>=</span> utils<span style=color:#f92672>.</span>ServingModule(model, size, imagenet_labels)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> predictions <span style=color:#f92672>=</span> serving_module<span style=color:#f92672>.</span>predict_labels(raw_images)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> predictions
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;labels&#39;</span>: <span style=color:#f92672>&lt;</span>tf<span style=color:#f92672>.</span>Tensor: shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>), dtype<span style=color:#f92672>=</span>string, numpy<span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>array([[<span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Egyptian cat&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;tiger cat&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;tabby&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;lynx&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Siamese cat&#39;</span>],
</span></span><span style=display:flex><span>       [<span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;military uniform&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;suit&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Windsor tie&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;pickelhaube&#39;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;bow tie&#39;</span>]], dtype<span style=color:#f92672>=</span>object)<span style=color:#f92672>&gt;</span>, <span style=color:#e6db74>&#39;probabilities&#39;</span>: <span style=color:#f92672>&lt;</span>tf<span style=color:#f92672>.</span>Tensor: shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>), dtype<span style=color:#f92672>=</span>float32, numpy<span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>array([[<span style=color:#ae81ff>8.2705331e-01</span>, <span style=color:#ae81ff>1.3128258e-01</span>, <span style=color:#ae81ff>4.1055005e-02</span>, <span style=color:#ae81ff>5.7081261e-04</span>,
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>1.8924713e-05</span>],
</span></span><span style=display:flex><span>       [<span style=color:#ae81ff>9.4001341e-01</span>, <span style=color:#ae81ff>4.8532788e-02</span>, <span style=color:#ae81ff>6.4066364e-03</span>, <span style=color:#ae81ff>2.0129983e-03</span>,
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>6.0433790e-04</span>]], dtype<span style=color:#f92672>=</span>float32)<span style=color:#f92672>&gt;</span>}
</span></span></code></pre></div><p>In this case, my custom serving module only get top-5 labels that have highest probabilities.</p><h3 id=3-save-the-custom-serving-module-as-savedmodel>3. Save the custom serving module as <code>SavedModel</code><a hidden class=anchor aria-hidden=true href=#3-save-the-custom-serving-module-as-savedmodel>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> model_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/home/hoang/Downloads/resnet_serving/101&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> default_signature <span style=color:#f92672>=</span> serving_module<span style=color:#f92672>.</span>__call__<span style=color:#f92672>.</span>get_concrete_function()
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> preprocess_signature <span style=color:#f92672>=</span> serving_module<span style=color:#f92672>.</span>predict_labels<span style=color:#f92672>.</span>get_concrete_function()
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> signatures <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#39;serving_default&#39;</span>: default_signature,
</span></span><span style=display:flex><span>                  <span style=color:#e6db74>&#39;serving_preprocess&#39;</span>: preprocess_signature}
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> tf<span style=color:#f92672>.</span>saved_model<span style=color:#f92672>.</span>save(serving_module, model_path, signatures<span style=color:#f92672>=</span>signatures)
</span></span><span style=display:flex><span>INFO:tensorflow:Assets written to: <span style=color:#f92672>/</span>home<span style=color:#f92672>/</span>hoang<span style=color:#f92672>/</span>Downloads<span style=color:#f92672>/</span>resnet_serving<span style=color:#f92672>/</span><span style=color:#ae81ff>101</span><span style=color:#f92672>/</span>assets
</span></span></code></pre></div><p>Verify the Resnet model serving:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ saved_model_cli show --dir <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>model_path<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --tag_set serve --all
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>MetaGraphDef with tag-set: <span style=color:#e6db74>&#39;serve&#39;</span> contains the following SignatureDefs:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>signature_def<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;__saved_model_init_op&#39;</span><span style=color:#f92672>]</span>:
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following input<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following output<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>    outputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;__saved_model_init_op&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_INVALID
</span></span><span style=display:flex><span>        shape: unknown_rank
</span></span><span style=display:flex><span>        name: NoOp
</span></span><span style=display:flex><span>  Method name is: 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>signature_def<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;serving_default&#39;</span><span style=color:#f92672>]</span>:
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following input<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>    inputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;x&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_FLOAT
</span></span><span style=display:flex><span>        shape: <span style=color:#f92672>(</span>-1, 224, 224, 3<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        name: serving_default_x:0
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following output<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>    outputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;output_0&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_FLOAT
</span></span><span style=display:flex><span>        shape: <span style=color:#f92672>(</span>-1, 1001<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        name: StatefulPartitionedCall:0
</span></span><span style=display:flex><span>  Method name is: tensorflow/serving/predict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>signature_def<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;serving_preprocess&#39;</span><span style=color:#f92672>]</span>:
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following input<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>    inputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;raw_images&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_STRING
</span></span><span style=display:flex><span>        shape: <span style=color:#f92672>(</span>-1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        name: serving_preprocess_raw_images:0
</span></span><span style=display:flex><span>  The given SavedModel SignatureDef contains the following output<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span>:
</span></span><span style=display:flex><span>    outputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;labels&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_STRING
</span></span><span style=display:flex><span>        shape: <span style=color:#f92672>(</span>-1, -1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        name: StatefulPartitionedCall_1:0
</span></span><span style=display:flex><span>    outputs<span style=color:#f92672>[</span><span style=color:#e6db74>&#39;probabilities&#39;</span><span style=color:#f92672>]</span> tensor_info:
</span></span><span style=display:flex><span>        dtype: DT_FLOAT
</span></span><span style=display:flex><span>        shape: <span style=color:#f92672>(</span>-1, -1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        name: StatefulPartitionedCall_1:1
</span></span><span style=display:flex><span>  Method name is: tensorflow/serving/predict
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Defined Functions:
</span></span><span style=display:flex><span>  Function Name: <span style=color:#e6db74>&#39;__call__&#39;</span>
</span></span><span style=display:flex><span>    Option <span style=color:#75715e>#1</span>
</span></span><span style=display:flex><span>      Callable with:
</span></span><span style=display:flex><span>        Argument <span style=color:#75715e>#1</span>
</span></span><span style=display:flex><span>          x: TensorSpec<span style=color:#f92672>(</span>shape<span style=color:#f92672>=(</span>None, 224, 224, 3<span style=color:#f92672>)</span>, dtype<span style=color:#f92672>=</span>tf.float32, name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;x&#39;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Function Name: <span style=color:#e6db74>&#39;predict_labels&#39;</span>
</span></span><span style=display:flex><span>    Option <span style=color:#75715e>#1</span>
</span></span><span style=display:flex><span>      Callable with:
</span></span><span style=display:flex><span>        Argument <span style=color:#75715e>#1</span>
</span></span><span style=display:flex><span>          raw_images: TensorSpec<span style=color:#f92672>(</span>shape<span style=color:#f92672>=(</span>None,<span style=color:#f92672>)</span>, dtype<span style=color:#f92672>=</span>tf.string, name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;raw_images&#39;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><p>Test loading and executing the <code>SavedModel</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> model <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>models<span style=color:#f92672>.</span>load_model(model_path)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> model<span style=color:#f92672>.</span>predict_labels(raw_images)
</span></span><span style=display:flex><span>{<span style=color:#e6db74>&#39;probabilities&#39;</span>: <span style=color:#f92672>&lt;</span>tf<span style=color:#f92672>.</span>Tensor: shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>), dtype<span style=color:#f92672>=</span>float32, numpy<span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>array([[<span style=color:#ae81ff>8.2705331e-01</span>, <span style=color:#ae81ff>1.3128258e-01</span>, <span style=color:#ae81ff>4.1055005e-02</span>, <span style=color:#ae81ff>5.7081261e-04</span>,
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>1.8924713e-05</span>],
</span></span><span style=display:flex><span>       [<span style=color:#ae81ff>9.4001341e-01</span>, <span style=color:#ae81ff>4.8532788e-02</span>, <span style=color:#ae81ff>6.4066364e-03</span>, <span style=color:#ae81ff>2.0129983e-03</span>,
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>6.0433790e-04</span>]], dtype<span style=color:#f92672>=</span>float32)<span style=color:#f92672>&gt;</span>, <span style=color:#e6db74>&#39;labels&#39;</span>: <span style=color:#f92672>&lt;</span>tf<span style=color:#f92672>.</span>Tensor: shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>), dtype<span style=color:#f92672>=</span>string, numpy<span style=color:#f92672>=</span>
</span></span><span style=display:flex><span>array([[<span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Egyptian cat&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;tiger cat&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;tabby&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;lynx&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Siamese cat&#39;</span>],
</span></span><span style=display:flex><span>       [<span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;military uniform&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;suit&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Windsor tie&#39;</span>, <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;pickelhaube&#39;</span>,
</span></span><span style=display:flex><span>        <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;bow tie&#39;</span>]], dtype<span style=color:#f92672>=</span>object)<span style=color:#f92672>&gt;</span>}
</span></span></code></pre></div><p>We can absolutely do the same with the Resnet50 model. Finally we have the custom serving module for Resnet model with two version, <code>50</code> and <code>101</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ tree /home/hoang/Downloads/resnet_serving
</span></span><span style=display:flex><span>├── <span style=color:#ae81ff>101</span>
</span></span><span style=display:flex><span>│   ├── assets
</span></span><span style=display:flex><span>│   ├── saved_model.pb
</span></span><span style=display:flex><span>│   └── variables
</span></span><span style=display:flex><span>│       ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>│       └── variables.index
</span></span><span style=display:flex><span>└── <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>    ├── assets
</span></span><span style=display:flex><span>    ├── saved_model.pb
</span></span><span style=display:flex><span>    └── variables
</span></span><span style=display:flex><span>        ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>        └── variables.index
</span></span><span style=display:flex><span><span style=color:#ae81ff>6</span> directories, <span style=color:#ae81ff>6</span> files
</span></span></code></pre></div><h3 id=4-deploying-the-savedmodel>4. Deploying the <code>SavedModel</code><a hidden class=anchor aria-hidden=true href=#4-deploying-the-savedmodel>#</a></h3><p>Now we will serving multiple versions of the Resnet model, by write model config <code>models.config</code> file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>model_config_list {
</span></span><span style=display:flex><span>  config {
</span></span><span style=display:flex><span>    name: &#39;resnet&#39;
</span></span><span style=display:flex><span>    base_path: &#39;/models/resnet/&#39;
</span></span><span style=display:flex><span>    model_platform: &#39;tensorflow&#39;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    model_version_policy {
</span></span><span style=display:flex><span>        specific {
</span></span><span style=display:flex><span>            versions: 50
</span></span><span style=display:flex><span>            versions: 101
</span></span><span style=display:flex><span>          }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    version_labels {
</span></span><span style=display:flex><span>        key: &#39;stable&#39;
</span></span><span style=display:flex><span>        value: 50
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    version_labels {
</span></span><span style=display:flex><span>        key: &#39;canary&#39;
</span></span><span style=display:flex><span>        value: 101
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Write the <code>docker-compose.yaml</code> file:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#39;3.2&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>tf-serving</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>tf_serving</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>tensorflow/serving:2.5.1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8501:8501&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8500:8500&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;/home/hoang/Downloads/resnet_serving:/models/resnet&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./models.config:/models/models.config&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file=/models/models.config&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file_poll_wait_seconds=60&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--allow_version_labels_for_unavailable_models&#39;</span>
</span></span></code></pre></div><p>By default TFS does not allow labelling of models that are not ready to serve. So usually you had to avoid including the labels in the config file and spin up the container (otherwise you&rsquo;ll get an error) and after the models were loaded for serving you could edit the config file to include labels. By setting <code>--allow_version_labels_for_unavailable_models</code> flag to true you avoid having to do this.</p><p>Deploying the model by <code>docker-compose</code> command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ docker-compose up -d
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>+<span style=color:#f92672>]</span> Running 2/2
</span></span><span style=display:flex><span> ⠿ Network tensorflow-serving-configuration_default  Created            0.2s
</span></span><span style=display:flex><span> ⠿ Container tf_serving                              Started            1.2s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ docker ps | grep tf_serving
</span></span><span style=display:flex><span>e1f6a5ed1276   tensorflow/serving:2.5.1   <span style=color:#e6db74>&#34;/usr/bin/tf_serving…&#34;</span>   About a minute ago   Up About a minute   0.0.0.0:8500-8501-&gt;8500-8501/tcp, :::8500-8501-&gt;8500-8501/tcp   tf_serving
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ docker logs -f tf_serving
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>2022-10-01 11:26:22.126759: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59<span style=color:#f92672>]</span> No warmup data file found at /models/resnet/50/assets.extra/tf_serving_warmup_requests
</span></span><span style=display:flex><span>2022-10-01 11:26:23.183213: I tensorflow_serving/model_servers/server.cc:393<span style=color:#f92672>]</span> Running gRPC ModelServer at 0.0.0.0:8500 ...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>warn<span style=color:#f92672>]</span> getaddrinfo: address family <span style=color:#66d9ef>for</span> nodename not supported
</span></span><span style=display:flex><span>2022-10-01 11:26:23.185253: I tensorflow_serving/model_servers/server.cc:414<span style=color:#f92672>]</span> Exporting HTTP/REST API at:localhost:8501 ...
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>evhttp_server.cc : 245<span style=color:#f92672>]</span> NET_LOG: Entering the event loop ...
</span></span></code></pre></div><h3 id=5-validating-the-deployed-model>5. Validating the deployed model<a hidden class=anchor aria-hidden=true href=#5-validating-the-deployed-model>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ curl -d @payloads/request-body.json -X POST http://localhost:8501/v1/models/resnet/versions/50:predict
</span></span><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;predictions&#34;</span>: <span style=color:#f92672>[</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;labels&#34;</span>: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;military uniform&#34;</span>, <span style=color:#e6db74>&#34;pickelhaube&#34;</span>, <span style=color:#e6db74>&#34;suit&#34;</span>, <span style=color:#e6db74>&#34;Windsor tie&#34;</span>, <span style=color:#e6db74>&#34;bearskin&#34;</span><span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;probabilities&#34;</span>: <span style=color:#f92672>[</span>0.453408211, 0.209194973, 0.193582058, 0.0409308933, 0.0137334978<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>Now ask for a prediction to the same model but this time using labels instead of versions. Notice that the URL changes slightly:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ curl -d @payloads/request-body.json -X POST http://localhost:8501/v1/models/resnet/labels/canary:predict
</span></span><span style=display:flex><span><span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;predictions&#34;</span>: <span style=color:#f92672>[</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;probabilities&#34;</span>: <span style=color:#f92672>[</span>0.940013, 0.0485330448, 0.00640664576, 0.0020130109, 0.000604341098<span style=color:#f92672>]</span>,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;labels&#34;</span>: <span style=color:#f92672>[</span><span style=color:#e6db74>&#34;military uniform&#34;</span>, <span style=color:#e6db74>&#34;suit&#34;</span>, <span style=color:#e6db74>&#34;Windsor tie&#34;</span>, <span style=color:#e6db74>&#34;pickelhaube&#34;</span>, <span style=color:#e6db74>&#34;bow tie&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><h3 id=6-advanced-model-server-configuration>6. Advanced model server configuration<a hidden class=anchor aria-hidden=true href=#6-advanced-model-server-configuration>#</a></h3><h4 id=61-savedmodel-warmup>6.1. SavedModel Warmup<a hidden class=anchor aria-hidden=true href=#61-savedmodel-warmup>#</a></h4><p>As soon as you have just deployed the model without a warm up, you can see the response time look like that:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ curl -d @payloads/request-body.json -X POST http://localhost:8501/v1/models/resnet/versions/50:predict -o /dev/null -s -w <span style=color:#e6db74>&#39;Total: %{time_total}s\n&#39;</span>
</span></span><span style=display:flex><span>Total: 1,423064s
</span></span></code></pre></div><p>To enable model warmup, you will use user-provided PredictionLogs in <code>assets.extra/</code> directory. Fisrtly, generating the PredictionLogs from module <code>utils/warmup_serving.py</code> and save into a file:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ python3 utils/warmup_serving.py
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ tree /home/hoang/Downloads/resnet_serving
</span></span><span style=display:flex><span>/home/hoang/Downloads/resnet_serving
</span></span><span style=display:flex><span>├── <span style=color:#ae81ff>101</span>
</span></span><span style=display:flex><span>│   ├── assets
</span></span><span style=display:flex><span>│   ├── assets.extra
</span></span><span style=display:flex><span>│   │   └── tf_serving_warmup_requests
</span></span><span style=display:flex><span>│   ├── saved_model.pb
</span></span><span style=display:flex><span>│   └── variables
</span></span><span style=display:flex><span>│       ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>│       └── variables.index
</span></span><span style=display:flex><span>└── <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>    ├── assets
</span></span><span style=display:flex><span>    ├── assets.extra
</span></span><span style=display:flex><span>    │   └── tf_serving_warmup_requests
</span></span><span style=display:flex><span>    ├── saved_model.pb
</span></span><span style=display:flex><span>    └── variables
</span></span><span style=display:flex><span>        ├── variables.data-00000-of-00001
</span></span><span style=display:flex><span>        └── variables.index
</span></span><span style=display:flex><span><span style=color:#ae81ff>8</span> directories, <span style=color:#ae81ff>8</span> files
</span></span></code></pre></div><p>Now we will test the model serving with a warm up</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e># Re-create the container</span>
</span></span><span style=display:flex><span>$ docker-compose up -d
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>+<span style=color:#f92672>]</span> Running 2/2
</span></span><span style=display:flex><span> ⠿ Network tensorflow-serving-configuration_default  Created            0.1s
</span></span><span style=display:flex><span> ⠿ Container tf_serving                              Started            0.8s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Trace logs</span>
</span></span><span style=display:flex><span>$ docker logs -f tf_serving
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>2022-10-02 06:53:31.495273: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:122<span style=color:#f92672>]</span> Finished reading warmup data <span style=color:#66d9ef>for</span> model at /models/resnet/50/assets.extra/tf_serving_warmup_requests. Number of warmup records read: 200. Elapsed time <span style=color:#f92672>(</span>microseconds<span style=color:#f92672>)</span>: 45988765.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Exec curl</span>
</span></span><span style=display:flex><span>curl -d @payloads/request-body.json -X POST http://localhost:8501/v1/models/resnet/versions/50:predict -o /dev/null -s -w <span style=color:#e6db74>&#39;Total: %{time_total}s\n&#39;</span>
</span></span><span style=display:flex><span>Total: 0,129297s
</span></span></code></pre></div><p>It is easy to see that a Warmup helps the model to start up faster.</p><h4 id=62-monitoring-configuration>6.2. Monitoring Configuration<a hidden class=anchor aria-hidden=true href=#62-monitoring-configuration>#</a></h4><p>TensorFlow Serving gives you the capability to connect to Prometheus to monitor metrics from your model server, by using the <code>--monitoring_config_file</code> flag to specify a <code>monitor.config</code> file containing a <code>MonitoringConfig</code> protocol buffer. It would look like that:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>prometheus_config {
</span></span><span style=display:flex><span>  enable: true,
</span></span><span style=display:flex><span>  path: &#34;/monitoring/prometheus/metrics&#34;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Next, configure Prometheus Server to listen to your model server by providing the following to its deployment manifest:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#39;3.2&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>tf-serving</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>tf_serving</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>tensorflow/serving:2.5.1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8501:8501&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8500:8500&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;/home/hoang/Downloads/resnet_serving:/models/resnet&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./models.config:/models/models.config&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./monitor.config:/models/monitor.config&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file=/models/models.config&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file_poll_wait_seconds=60&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--allow_version_labels_for_unavailable_models&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--monitoring_config_file=/models/monitor.config&#39;</span>
</span></span></code></pre></div><p>Deploying your model server:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ docker-compose up -d
</span></span></code></pre></div><p>You will also be able to check if the metrics are correctly exported at http://localhost:8501/monitoring/prometheus/metrics. It&rsquo;s look like that:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span># TYPE :tensorflow:api:op:using_fake_quantization gauge
</span></span><span style=display:flex><span># TYPE :tensorflow:cc:saved_model:load_attempt_count counter
</span></span><span style=display:flex><span>:tensorflow:cc:saved_model:load_attempt_count{model_path=&#34;/models/resnet/101&#34;,status=&#34;success&#34;} 1
</span></span><span style=display:flex><span>:tensorflow:cc:saved_model:load_attempt_count{model_path=&#34;/models/resnet/50&#34;,status=&#34;success&#34;} 1
</span></span><span style=display:flex><span># TYPE :tensorflow:cc:saved_model:load_latency counter
</span></span><span style=display:flex><span>:tensorflow:cc:saved_model:load_latency{model_path=&#34;/models/resnet/101&#34;} 3020490
</span></span><span style=display:flex><span>:tensorflow:cc:saved_model:load_latency{model_path=&#34;/models/resnet/50&#34;} 1455731
</span></span><span style=display:flex><span># TYPE :tensorflow:cc:saved_model:load_latency_by_stage histogram
</span></span><span style=display:flex><span>:tensorflow:serving:runtime_latency_bucket{model_name=&#34;resnet&#34;,API=&#34;Predict&#34;,runtime=&#34;TF1&#34;,le=&#34;10&#34;} 0
</span></span></code></pre></div><h4 id=63-batching>6.3. Batching<a hidden class=anchor aria-hidden=true href=#63-batching>#</a></h4><p>TensorFlow Serving allows you to perform request batching by setting the <code>--enable_batching</code> and <code>--batching_parameters_file</code> flags, where the <code>batching.config</code> file may look like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>max_batch_size { value: 128 }
</span></span><span style=display:flex><span>batch_timeout_micros { value: 0 }
</span></span><span style=display:flex><span>max_enqueued_batches { value: 1000000 }
</span></span><span style=display:flex><span>num_batch_threads { value: 4 }
</span></span></code></pre></div><p>Next, configure batching online requests together for model server by providing the following to its deployment manifest:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>version</span>: <span style=color:#e6db74>&#39;3.2&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>services</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>tf-serving</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>container_name</span>: <span style=color:#ae81ff>tf_serving</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>tensorflow/serving:2.5.1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ports</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8501:8501&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;8500:8500&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumes</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;/home/hoang/Downloads/resnet_serving:/models/resnet&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./models.config:/models/models.config&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./monitor.config:/models/monitor.config&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#34;./batching.config:/models/batching.config&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file=/models/models.config&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--model_config_file_poll_wait_seconds=60&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--allow_version_labels_for_unavailable_models&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--monitoring_config_file=/models/monitor.config&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--batching_parameters_file=/models/batching.config&#39;</span>
</span></span><span style=display:flex><span>      - <span style=color:#e6db74>&#39;--enable_batching&#39;</span>
</span></span></code></pre></div><h3 id=optional-grpc-vs-rest>(Optional) gRPC vs. REST<a hidden class=anchor aria-hidden=true href=#optional-grpc-vs-rest>#</a></h3><p>In this section, we will benchmark the inference time between gRPC and REST by run the python script:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>$ python3 utils/benchmark.py
</span></span><span style=display:flex><span><span style=color:#f92672>==========</span> Test on <span style=color:#ae81ff>250</span> records <span style=color:#f92672>==========</span>
</span></span><span style=display:flex><span>Predict gRPC in ...s
</span></span><span style=display:flex><span>Predict REST api in ...s
</span></span></code></pre></div><p>You can get full source code <a href=https://github.com/dang99/mlops-labs/tree/main/tensorflow-serving-configuration>here</a>!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dang99.github.io/tags/tensorflow/>TensorFlow</a></li><li><a href=https://dang99.github.io/tags/model-serving/>Model Serving</a></li></ul><nav class=paginav><a class=prev href=https://dang99.github.io/posts/canary_release_tensorflow_k8s/><span class=title>« Prev</span><br><span>Deploying TensorFlow model as Canary Releases Kubernetes and Istio</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on x" href="https://x.com/intent/tweet/?text=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving&amp;url=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f&amp;hashtags=TensorFlow%2cModelServing"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f&amp;title=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving&amp;summary=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving&amp;source=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f&title=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on whatsapp" href="https://api.whatsapp.com/send?text=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving%20-%20https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on telegram" href="https://telegram.me/share/url?text=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving&amp;url=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Prepare and Deploy a TensorFlow Model to Tensorflow Serving on ycombinator" href="https://news.ycombinator.com/submitlink?t=Prepare%20and%20Deploy%20a%20TensorFlow%20Model%20to%20Tensorflow%20Serving&u=https%3a%2f%2fhoangph3.github.io%2fposts%2ftensorflow_serving_configuration%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://dang99.github.io>Hoangph3's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>